{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving a Keras Resnet Model\n",
    "\n",
    "Keras is a high level API that can be used to build deep neural nets with only a few lines of code, and supports a number of [backends](https://keras.io/backend/) for computation (TensorFlow, Theano, and CNTK). Keras also contains a library of pre-trained models, including a Resnet model with 50-layers, trained on the ImageNet dataset, which we will use for this exercise. \n",
    "\n",
    "This notebook teaches how to create a servable version of the Imagenet Resnet50 model in Keras using the TensorFlow backend. The servable model can be served using [TensorFlow Serving](https://www.tensorflow.org/serving/), which runs very efficiently in C++ and supports multiple platforms (different OSes, as well as hardware with different types of accelerators such as GPUs). The model will need to handle RPC prediction calls coming from a client that sends requests containing a batch of jpeg images. \n",
    "\n",
    "See https://github.com/keras-team/keras/blob/master/keras/applications/resnet50.py for the implementation of ResNet50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble\n",
    "\n",
    "Import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras libraries\n",
    "import keras.applications.resnet50 as resnet50\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Import TensorFlow saved model libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import utils\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants\n",
    "from tensorflow.python.saved_model.signature_def_utils_impl import build_signature_def, predict_signature_def\n",
    "from tensorflow.contrib.session_bundle import exporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DEFAULT_IMAGE_SIZE = 224  # Default width and height of input images to ResNet model\n",
    "_LABEL_CLASSES = 1001  # Number of classes that model predicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the Output Directory\n",
    "\n",
    "Set a version number and directory for the output of the servable model. Note that with TensorFlow, if you've successfully saved the servable in a directory, trying to save another servable will fail hard. You always want to increment your version number, or otherwise delete the output directory and re-run the servable creation code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION_NUMBER = 1  #Increment this if you want to generate more than one servable model\n",
    "SERVING_DIR = \"keras_servable/\" + str(VERSION_NUMBER)\n",
    "SAMPLE_DIR = \"../client\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Servable Model from Keras\n",
    "\n",
    "Keras has a prepackaged ImageNet-trained ResNet50 model which takes in a 4d input tensor (i.e. a tensor of RGB-color images) and outputs a list of class probabilities for all of the classes.\n",
    "\n",
    "We will create a servable model whose input takes in a batch of jpeg-encoded images, and outputs a dictionary containing the top k classes and probabilities for each image in the batch. We've refactored the input preprocessing and output postprocessing into helper functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions for Building a TensorFlow Graph\n",
    "\n",
    "TensorFlow is essentially a computation graph with variables and states. The graph must be built before it can ingest and process data. Typically, a TensorFlow graph will contain a set of input nodes (called placeholders) from which data can be ingested, and a set of TensorFlow functions that take existing nodes as inputs and produces a dependent node that performs a computation on the input nodes. Each node can be referenced as an \"output\" node through which processed data can be read.\n",
    "\n",
    "It is often useful to create helper functions for building a TensorFlow graphs for two reasons:\n",
    "\n",
    "1. Modularity: you can reuse functions in different places; for instance, a different image model or ResNet architecture can reuse functions.\n",
    "2. Testability: you can attach placeholders at the input of graph building helper functions, and read the output to ensure that your result matches expected behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function: convert JPEG strings to Normalized 3D Tensors\n",
    "\n",
    "The client (resnet_client.py) sends jpeg encoded images into an array of jpegs (each entry a string) to send to the server. These jpegs are all appropriately resized to 224x224x3, and do not need resizing on the server side to enter into the ResNet model. However, the ResNet50 model was trained with pixel values normalized using a predefined method in the Keras resnet50 package (resnet50.preprocess_input()). We will need to extract the raw 3D tensor from each jpeg string and normalize the values.\n",
    "\n",
    "**Exercise:** Add a command in the helper function to build a node that decodes a jpeg string into a 3D RGB image tensor.\n",
    "\n",
    "**Useful References:**\n",
    "* [tf.image module](https://www.tensorflow.org/api_guides/python/image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing helper function similar to `resnet_training_to_serving_solution.ipynb`.\n",
    "\n",
    "def build_jpeg_to_image_graph(jpeg_image):\n",
    "  \"\"\"Build graph elements to preprocess an image by subtracting out the mean from all channels.\n",
    "  Args:\n",
    "    image: A jpeg-formatted byte stream represented as a string.\n",
    "  Returns:\n",
    "    A 3d tensor of image pixels normalized for the Keras ResNet50 model.\n",
    "      The canned ResNet50 pretrained model was trained after running\n",
    "      keras.applications.resnet50.preprocess_input in 'caffe' mode, which\n",
    "      flips the RGB channels and subtracts out the channel means [103.939, 116.779, 123.68].\n",
    "      There is no normalizing on the range.\n",
    "  \"\"\"\n",
    "  image = ???\n",
    "  image = tf.to_float(image)\n",
    "  image = resnet50.preprocess_input(image)  \n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit test the helper function\n",
    "\n",
    "**Exercise:** We are going to construct an input [placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) node in our TensorFlow graph to read data into TensorFlow, and use the helper function to attach computational elements to the input node, resulting in an output node where data is collected. Next, we will then run the graph by providing sample input into the placeholder (Input data can be python floats, ints, strings, numpy arrays, ndarrays, etc.), and returning the value at the output node.\n",
    "\n",
    "A placeholder can store a Tensor of arbitrary dimension, and arbitrary length in any dimension. \n",
    "\n",
    "An example of a placeholder that holds a 1d tensor of floating values is:\n",
    "\n",
    "```\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[10], 'my_input_node')\n",
    "```\n",
    "\n",
    "An example of a 2d tensor (matrix) of dimensions 10x20 holding string values is:\n",
    "```\n",
    "x = tf.placeholder(dtype=tf.string, shape=[10, 20], 'my_string_matrix')\n",
    "```\n",
    "\n",
    "Note that we assigned a Python variable x to be a pointer to the placeholder, but simply calling tf.placeholder() with a named element would create an element in the TensorFlow graph that can be referenced in a global dictionary as 'my_input_node'. However, it helps to keep a Python pointer to keep track of the element without having to and pass it into helper functions. \n",
    "\n",
    "Any dependent node in the graph can serve as an output node. For instance, passing an input node x through `y = build_jpeg_to_image_graph(x)` would return a node referenced by python variable y which is the result of processing the input through the graph built by the helper function. When we run the test graph with real data below, you will see how to return the output of y.\n",
    "\n",
    "**Remember:** TensorFlow helper functions are used to help construct a computational graph! build_jpeg_to_image_graph() does not return a 3D array. It returns a graph node that returns a 3D array after processing a jpeg-encoded string!**\n",
    "\n",
    "**Useful References:**\n",
    "\n",
    "[TensorFlow shapes](https://www.tensorflow.org/guide/tensors#shape), [TensorFlow data types](https://www.tensorflow.org/api_docs/python/tf/DType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining input test graph nodes: only needs to be run once!\n",
    "test_jpeg_ph = ???  # A placeholder for a single string, which is a dimensionless (0D) tensor.\n",
    "test_decoded_tensor = ??? # Output node, which returns output of the jpeg to image graph.\n",
    "\n",
    "# Print the graph elements to check shapes. ? indicates that TensorFlow does not know the length of those dimensions.\n",
    "print(test_jpeg_ph)\n",
    "print(test_decoded_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Test Graph\n",
    "\n",
    "To run data through a test graph, a TensorFlow session must be created. TensorFlow will only run a portion of the graph that is required to map a set of inputs defined by a dictionary with entries of type {placeholder_node : python data}, and an output graph node (or list of graph nodes), e.g.:\n",
    "\n",
    "```\n",
    "with tf.Session() as sess:\n",
    "    sess.run(output_node,\n",
    "             {placeholder_1: input_data_1, placeholder_2: input_data_2, ...})\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```\n",
    "with tf.Session() as sess:\n",
    "    sess.run([output_node_1, output_node_2, ...],\n",
    "             {placeholder_1: input_data_1, placeholder_2: input_data_2, ...})\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**Exercise:** Let's read a jpeg image as an encoded string, pass it into the input placeholder, and return a 3D tensor result which is the normalized image. The expected image size is 224x224x3. Please add more potentially useful assert statements to test the output.\n",
    "\n",
    "**Hint:** The ??? below are just examples of possible assertions you can make about the range of output values in the preprocessed image. The more robust the assertions, the better you can validate your code! See the documentation for build_jpeg_to_image_graph() above for a description of how the resnet50.preprocess_image() function transforms images to fill in the ??? below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the graph! Validate the result of the function using a sample image SAMPLE_DIR/cat_sample.jpg\n",
    "ERROR_TOLERANCE = 1e-4\n",
    "\n",
    "with open(os.path.join(SAMPLE_DIR, \"cat_sample.jpg\"), \"rb\") as imageFile:\n",
    "    jpeg_str = imageFile.read()\n",
    "    with tf.Session() as sess:\n",
    "        result = sess.run(test_decoded_tensor, feed_dict={test_jpeg_ph: jpeg_str})\n",
    "        assert result.shape == (224, 224, 3)\n",
    "        # TODO: Replace with assert statements to check max and min normalized pixel values\n",
    "        assert result.max() <= ??? + ERROR_TOLERANCE  # Max pixel value after subtracting mean\n",
    "        assert result.min() >= ??? - ERROR_TOLERANCE  # Min pixel value after subtracting mean\n",
    "        print('Hooray! JPEG decoding test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "\n",
    "The approach above uses vanilla TensorFlow to perform unit testing. You may notice that the code is more verbose than ideal, since you have to create a session, feed input through a dictionary, etc. We encourage the student to investigate some options below at a later time: \n",
    "\n",
    "[TensorFlow Eager](https://research.googleblog.com/2017/10/eager-execution-imperative-define-by.html) was introduced in TensorFlow 1.5 as a way to execute TensorFlow graphs in a way similar to numpy operations. After testing individual parts of the graph using Eager, you will need to rebuild a graph with the Eager option turned off in order to build a performance optimized TensorFlow graph. Also, keep in mind that you will need another virtual environment with TensorFlow 1.5 in order to run eager execution, which may not be compatible with TensorFlow Serving 1.4 used in this tutorial.\n",
    "\n",
    "[TensorFlow unit testing](https://www.tensorflow.org/api_guides/python/test) is a more software engineer oriented approach to run tests. By writing test classes that can be invoked individually when building the project, calling tf.test.main() will run all tests and return a list of ones that succeeded and failed, allowing you to inspect errors. Because we are in a notebook environment, such a test would not succeed due to an already running kernel that tf.test cannot access. The tests must be run from the command line, e.g. `python test_my_graph.py`.\n",
    "\n",
    "We've provided both eager execution and unit test examples in the [testing](./testing) directory showing how to unit test various components in this notebook. Note that because these examples contain the solution to exercises below, please complete all notebook exercises prior to reading through these examples.\n",
    "\n",
    "Now that we know how to run TensorFlow tests, let's create and test more helper functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function: Preprocessing Server Input\n",
    "\n",
    "The server receives a client request in the form of a dictionary {'images': 1D_tensor_of_jpeg_encoded_strings}, which must be preprocessed into a 4D tensor before feeding into the Keras ResNet50 model.\n",
    "\n",
    "**Exercise**: We will be using [a ResNet client](./client/resnet_client.py) to send requests to our server. You will need to create a graph to preprocess client requests to be compliant with the client. Using tf.map_fn and build_jpeg_to_image_graph, fill in the missing line (marked ???) to convert the client request into an array of 3D floating-point, preprocessed tensor. The following lines stack and reshape this array into a 4D tensor.\n",
    "\n",
    "**Useful References:**\n",
    "* [tf.map_fn](https://www.tensorflow.org/api_docs/python/tf/map_fn)\n",
    "* [tf.DType](https://www.tensorflow.org/api_docs/python/tf/DType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(jpeg_tensor):\n",
    "    processed_images = ???  # Convert a 1D-tensor of JPEGs to a list of 3D tensors\n",
    "    processed_images = tf.stack(processed_images)  # Convert list of 3D tensors to tensor of tensors (4D tensor)\n",
    "    processed_images = tf.reshape(tensor=processed_images,  # Reshape to ensure TF graph knows the final dimensions\n",
    "                                shape=[-1, _DEFAULT_IMAGE_SIZE, _DEFAULT_IMAGE_SIZE, 3])\n",
    "    return processed_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Test the Input Preprocessing Helper Function\n",
    "\n",
    "**Exercise**: Construct a TensorFlow unit test graph for the input function.\n",
    "\n",
    "**Hint:** the input node test_jpeg_tensor should be a [tf.placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder). You need to define the `shape` parameter in tf.placeholder. `None` inside an array indicates that the length can vary along that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Test Input Preprocessing Network: only needs to be run once!\n",
    "test_jpeg_tensor = ???  # A placeholder for a 1D tensor (of arbitrary length) of jpeg-encoded strings.\n",
    "test_processed_images = ???  # Output node, which returns a 4D tensor after processing.\n",
    "\n",
    "# Print the graph elements to check shapes. ? indicates that TensorFlow does not know the length of those dimensions.\n",
    "print(test_jpeg_tensor)\n",
    "print(test_processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test network using a sample image SAMPLE_DIR/cat_sample.jpg\n",
    "\n",
    "with open(os.path.join(SAMPLE_DIR, \"cat_sample.jpg\"), \"rb\") as imageFile:\n",
    "    jpeg_str = imageFile.read()\n",
    "    with tf.Session() as sess:\n",
    "        result = sess.run(test_processed_images, feed_dict={test_jpeg_tensor: np.array([jpeg_str, jpeg_str])})  # Duplicate for length 2 array\n",
    "        assert result.shape == (2, 224, 224, 3)  # 4D tensor with first dimension length 2, since we have 2 images\n",
    "        # TODO: add a test for min and max normalized pixel values\n",
    "        assert result.max() <= ??? + ERROR_TOLERANCE  # Max pixel value after subtracting mean\n",
    "        assert result.min() >= ??? - ERROR_TOLERANCE  # Min pixel value after subtracting mean\n",
    "        # TODO: add a test to verify that the resulting tensor for image 0 and image 1 are identical.\n",
    "        assert result[0].all() == result[1].all()\n",
    "        print('Hooray! Input unit test succeeded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function: Postprocess Server Output\n",
    "\n",
    "**Exercise:** The Keras model returns a 1D tensor of probabilities for each class. We want to wrote a postprocess_output() that returns only the top k classes and probabilities.\n",
    "\n",
    "**Useful References:**\n",
    "* [tf.nn.top_k](https://www.tensorflow.org/api_docs/python/tf/nn/top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 5\n",
    "\n",
    "def postprocess_output(model_output):\n",
    "    '''Return top k classes and probabilities.'''\n",
    "    top_k_probs, top_k_classes = ???\n",
    "    return {'classes': top_k_classes, 'probabilities': top_k_probs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Test the Output Postprocessing Helper Function\n",
    "\n",
    "**Exercise:** Fill in the shape field for the model output, which should be a 1D tensor of probabilities.\n",
    "\n",
    "**Hint:** how many image classes are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Test Output Postprocessing Network: only needs to be run once!\n",
    "test_model_output = tf.placeholder(dtype=tf.float32, shape=???, name='test_logits_tensor')\n",
    "test_prediction_output = postprocess_output(test_model_output)\n",
    "\n",
    "# Print the graph elements to check shapes.\n",
    "print(test_model_output)\n",
    "print(test_prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy testing framework for float comparisons\n",
    "import numpy.testing as npt\n",
    "\n",
    "# Run test network\n",
    "# Input a tensor with clear winners, and perform checks\n",
    "\n",
    "# Be very specific about what is expected from your mock model.\n",
    "model_probs = np.ones(???)  # TODO: use the same dimensions as your test_model_output placeholder.\n",
    "model_probs[2] = 2.5  # TODO: you can create your own tests as well\n",
    "model_probs[5] = 3.5\n",
    "model_probs[10] = 4\n",
    "model_probs[49] = 3\n",
    "model_probs[998] = 2\n",
    "TOTAL_WEIGHT = np.sum(model_probs)\n",
    "model_probs = model_probs / TOTAL_WEIGHT\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(test_prediction_output, {test_model_output: model_probs})\n",
    "    classes = result['classes']\n",
    "    probs = result['probabilities']\n",
    "    # Check values\n",
    "    assert len(probs) == 5\n",
    "    npt.assert_almost_equal(probs[0], model_probs[10])\n",
    "    npt.assert_almost_equal(probs[1], model_probs[5])\n",
    "    npt.assert_almost_equal(probs[2], model_probs[49])\n",
    "    npt.assert_almost_equal(probs[3], model_probs[2])\n",
    "    npt.assert_almost_equal(probs[4], model_probs[998])\n",
    "    assert len(classes) == 5\n",
    "    assert classes[0] == 10\n",
    "    assert classes[1] == 5\n",
    "    assert classes[2] == 49\n",
    "    assert classes[3] == 2\n",
    "    assert classes[4] == 998\n",
    "    print('Hooray! Output unit test succeeded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Keras Model and Build the Graph\n",
    "\n",
    "The Keras Model uses TensorFlow as its backend, and therefore its inputs and outputs can be treated as elements of a TensorFlow graph. In other words, you can provide an input that is a TensorFlow tensor, and read the model output like a TensorFlow tensor!\n",
    "\n",
    "**Exercise**: Build the end to end network by filling in the TODOs below.\n",
    "\n",
    "**Useful References**:\n",
    "* [Keras ResNet50 API](https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50)\n",
    "* [Keras Model class API](https://faroit.github.io/keras-docs/1.2.2/models/model/): ResNet50 model inherits this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a placeholder for your arbitrary-length 1D Tensor of JPEG strings\n",
    "images = tf.placeholder(???)\n",
    "\n",
    "# TODO: Call preprocess_input to return processed_images\n",
    "processed_images = ???\n",
    "\n",
    "# Load (and download if missing) the ResNet50 Keras Model (may take a while to run)\n",
    "# TODO: Use processed_images as input\n",
    "model = resnet50.ResNet50(???)\n",
    "# Rename the model to 'resnet' for serving\n",
    "model.name = 'resnet'\n",
    "\n",
    "# TODO: Call postprocess_output on the output of the model to create predictions to send back to the client\n",
    "predictions = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Input-Output Signature\n",
    "\n",
    "**Exercise:** The final step to creating a servable model is to define the end-to-end input and output API. Edit the inputs and outputs parameters to predict_signature_def below to ensure that the signature correctly handles client request. The inputs parameter should be a dictionary {'images': tensor_of_strings}, and the outputs parameter a dictionary {'classes': tensor_of_top_k_classes, 'probabilities': tensor_of_top_k_probs}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a saved model builder as an endpoint to dataflow execution\n",
    "builder = saved_model_builder.SavedModelBuilder(SERVING_DIR)\n",
    "\n",
    "# TODO: set the inputs and outputs parameters in predict_signature_def()\n",
    "signature = predict_signature_def(inputs=???,\n",
    "                                  outputs=???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the Servable Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "with K.get_session() as sess:\n",
    "    builder.add_meta_graph_and_variables(sess=sess,\n",
    "                                         tags=[tag_constants.SERVING],\n",
    "                                         signature_def_map={'predict': signature})\n",
    "    builder.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
